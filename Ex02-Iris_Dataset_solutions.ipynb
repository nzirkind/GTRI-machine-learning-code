{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iris Dataset\n",
    "\n",
    "![](http://5047-presscdn.pagely.netdna-cdn.com/wp-content/uploads/2015/04/iris_petal_sepal.png)\n",
    "\n",
    "From Wikipedia:\n",
    "\n",
    "> The Iris flower data set or Fisher's Iris data set is a multivariate data set introduced by the British statistician and biologist Ronald Fisher in his 1936 paper The use of multiple measurements in taxonomic problems as an example of linear discriminant analysis. It is sometimes called Anderson's Iris data set because Edgar Anderson collected the data to quantify the morphologic variation of Iris flowers of three related species. Two of the three species were collected in the GaspÃ© Peninsula \"all from the same pasture, and picked on the same day and measured at the same time by the same person with the same apparatus\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas\n",
    "\n",
    "Pandas is a library modeled after the R dataframe API that enables the quick exploration and processing of heterogenous data.  \n",
    "\n",
    "One of the many great things about pandas is that is has many functions for grabbing data--including functions for grabbing data from the internet.  In the cell below, we grabbed data from the [https://archive.ics.uci.edu/ml/datasets/Iris](UCI Machine Leanring Repository), which has the data as a csv (without headers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\"\n",
    "\n",
    "df = pd.read_csv(url,names=['sepal_length',\n",
    "                            'sepal_width',\n",
    "                            'petal_length',\n",
    "                            'petal_width',\n",
    "                            'species'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `read_html`\n",
    "\n",
    "Wikipedia has the same dataset as a html table at [https://en.wikipedia.org/wiki/Iris_flower_data_set](https://en.wikipedia.org/wiki/Iris_flower_data_set).  Let's use [http://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_html.html](`pd.read_html`) to grab the data directly from Wikipedia.\n",
    "\n",
    "You might have to run the following command first:\n",
    "```\n",
    "conda install html5lib BeautifulSoup4 lxml\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "df_w = pd.read_html('https://en.wikipedia.org/wiki/Iris_flower_data_set',header=0)[0]\n",
    "df_w.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting\n",
    "\n",
    "Let's use pandas to plot the sepal_length vs the petal_length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pylab as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.scatter(df.sepal_length, df.petal_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It would be nice to encode by color and plot all combinations of values, but this isn't easy with matplotlib.  Instead, let's use `seaborn` (`conda install seaborn`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.pairplot(df,vars=['sepal_length',\n",
    "                    'sepal_width',\n",
    "                    'petal_length',\n",
    "                    'petal_width'],hue='species')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.swarmplot(x=\"species\", y=\"petal_length\", data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pandas.tools.plotting import radviz\n",
    "radviz(df, \"species\",)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***Excercise***\n",
    "\n",
    "Visit the [https://seaborn.pydata.org/](seaborn site) and make two new plots with this Iris dataset using seaborn functions we haven't used above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Plot 1 Here\n",
    "sns.violinplot(x=\"species\", y=\"petal_length\", data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Plot 2 Here\n",
    "sns.interactplot(\"petal_length\", 'petal_width', \"sepal_width\", data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification\n",
    "\n",
    "Let's say that we are an amature botonist and we'd like to determine the specied of Iris in our front yard, but that all we have available to us to make that classification is this dataset and a ruler.\n",
    "\n",
    "\n",
    "### Approach\n",
    "\n",
    "This is a classic machine learning / classification problem where we want to used a collection of \"labeled\" data to help us sort through new data that we receive.  In this case, the new data is a set of four measurements for a flower in our yard.  \n",
    "\n",
    "\n",
    "Because we have labeled data, this is a \"supervised leanring\" problem.  If we did not know which species each point in the dataset belonged to, we could still use machine learning for \"unsupervised learning\".\n",
    "\n",
    "Let's reimport the data using scikit learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets, svm\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target.astype(float)\n",
    "\n",
    "\n",
    "# keep only two features and keep only two species\n",
    "X = X[y != 0, :2]\n",
    "y = y[y != 0]\n",
    "\n",
    "X,y, X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try Different Classifiers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# fit the model\n",
    "for fig_num, kernel in enumerate(('linear', 'rbf', 'poly')):\n",
    "    clf = svm.SVC(kernel=kernel, gamma=10)\n",
    "    clf.fit(X, y)\n",
    "\n",
    "    plt.figure(fig_num)\n",
    "    plt.clf()\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, zorder=10)\n",
    "\n",
    "    plt.axis('tight')\n",
    "    x_min = X[:, 0].min()\n",
    "    x_max = X[:, 0].max()\n",
    "    y_min = X[:, 1].min()\n",
    "    y_max = X[:, 1].max()\n",
    "\n",
    "    XX, YY = np.mgrid[x_min:x_max:200j, y_min:y_max:200j]\n",
    "    Z = clf.decision_function(np.c_[XX.ravel(), YY.ravel()])\n",
    "\n",
    "    # Put the result into a color plot\n",
    "    Z = Z.reshape(XX.shape)\n",
    "    plt.pcolormesh(XX, YY, Z > 0, cmap=plt.cm.Paired)\n",
    "    plt.contour(XX, YY, Z, colors=['k', 'k', 'k'], linestyles=['--', '-', '--'],\n",
    "                levels=[-.5, 0, .5])\n",
    "\n",
    "    plt.title(kernel)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which Classifier is Best?\n",
    "\n",
    "First, let's predict the species from the measurements.  Because the classifier is clearly not perfect, we expect some mis-classifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X)\n",
    "\n",
    "print(y,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inaccuracy Score\n",
    "\n",
    "Because we only have two classes, we can find the accuracy by taking the mean of the magnitude of the difference.  This value is percent of time we are inaccurate. A lower score is better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for kernel in ('linear', 'rbf', 'poly'):\n",
    "    clf = svm.SVC(kernel=kernel, gamma=10)\n",
    "    clf.fit(X, y)\n",
    "    y_pred = clf.predict(X)\n",
    "    print(kernel,np.mean(np.abs(y-y_pred))*100,'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***Excercise***\n",
    "\n",
    "In the above code we excluded `species==0` and we only classified based on the sepal dimensions.  Complete the following:\n",
    "\n",
    "- Copy the code cells from above and exclude `species==1`\n",
    "- Copy the code cells from above and use the petal dimensions for classification\n",
    "\n",
    "For each case, use the inaccuracy score to see how good the classification works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## species==1\n",
    "\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target.astype(float)\n",
    "\n",
    "# keep only two features and keep only two species\n",
    "X = X[y != 1, :2] # changed here\n",
    "y = y[y != 1] # changed here\n",
    "\n",
    "# fit the model\n",
    "for fig_num, kernel in enumerate(('linear', 'rbf', 'poly')):\n",
    "    clf = svm.SVC(kernel=kernel, gamma=10)\n",
    "    clf.fit(X, y)\n",
    "\n",
    "    plt.figure(fig_num)\n",
    "    plt.clf()\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, zorder=10)\n",
    "\n",
    "    plt.axis('tight')\n",
    "    x_min = X[:, 0].min()\n",
    "    x_max = X[:, 0].max()\n",
    "    y_min = X[:, 1].min()\n",
    "    y_max = X[:, 1].max()\n",
    "\n",
    "    XX, YY = np.mgrid[x_min:x_max:200j, y_min:y_max:200j]\n",
    "    Z = clf.decision_function(np.c_[XX.ravel(), YY.ravel()])\n",
    "\n",
    "    # Put the result into a color plot\n",
    "    Z = Z.reshape(XX.shape)\n",
    "    plt.pcolormesh(XX, YY, Z > 0, cmap=plt.cm.Paired)\n",
    "    plt.contour(XX, YY, Z, colors=['k', 'k', 'k'], linestyles=['--', '-', '--'],\n",
    "                levels=[-.5, 0, .5])\n",
    "\n",
    "    plt.title(kernel)\n",
    "    \n",
    "    y_pred = clf.predict(X)\n",
    "    print(kernel,np.mean(np.abs(y-y_pred))*100,'%')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## petals\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target.astype(float)\n",
    "\n",
    "# keep only two features and keep only two species\n",
    "X = X[y != 0, 2:] # changed here\n",
    "y = y[y != 0] \n",
    "\n",
    "# fit the model\n",
    "for fig_num, kernel in enumerate(('linear', 'rbf', 'poly')):\n",
    "    clf = svm.SVC(kernel=kernel, gamma=10)\n",
    "    clf.fit(X, y)\n",
    "\n",
    "    plt.figure(fig_num)\n",
    "    plt.clf()\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, zorder=10)\n",
    "\n",
    "    plt.axis('tight')\n",
    "    x_min = X[:, 0].min()\n",
    "    x_max = X[:, 0].max()\n",
    "    y_min = X[:, 1].min()\n",
    "    y_max = X[:, 1].max()\n",
    "\n",
    "    XX, YY = np.mgrid[x_min:x_max:200j, y_min:y_max:200j]\n",
    "    Z = clf.decision_function(np.c_[XX.ravel(), YY.ravel()])\n",
    "\n",
    "    # Put the result into a color plot\n",
    "    Z = Z.reshape(XX.shape)\n",
    "    plt.pcolormesh(XX, YY, Z > 0, cmap=plt.cm.Paired)\n",
    "    plt.contour(XX, YY, Z, colors=['k', 'k', 'k'], linestyles=['--', '-', '--'],\n",
    "                levels=[-.5, 0, .5])\n",
    "\n",
    "    plt.title(kernel)\n",
    "    \n",
    "    y_pred = clf.predict(X)\n",
    "    print(kernel,np.mean(np.abs(y-y_pred))*100,'%')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering\n",
    "\n",
    "Instead of using the labels, we could ignor the labels and do blind clustering on the dataset. Let's try that with sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target.astype(float)\n",
    "estimators = {'k_means_iris_3': KMeans(n_clusters=3),\n",
    "              'k_means_iris_8': KMeans(n_clusters=8),\n",
    "              'dbscan_iris_1': DBSCAN(eps=1)}\n",
    "\n",
    "for name, est in estimators.items():\n",
    "    est.fit(X)\n",
    "    labels = est.labels_\n",
    "    df[name] = labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Clusters\n",
    "\n",
    "Now let's visualize how we did.  We'd hope that the cluster color would be as well-seperated as the original data labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.pairplot(df,vars=['sepal_length',\n",
    "                    'sepal_width',\n",
    "                    'petal_length',\n",
    "                    'petal_width'],hue='dbscan_iris_1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy\n",
    "\n",
    "The plot looks good, but it isn't clear how good the labels are until we compare them with the true labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import homogeneity_score\n",
    "\n",
    "for name, est in estimators.items():\n",
    "    print('completeness', name, homogeneity_score(df[name],df['species']))\n",
    "    print('homogeneity', name, homogeneity_score(df['species'],df[name]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***Excercise***\n",
    "\n",
    "Visit [http://scikit-learn.org/stable/auto_examples/cluster/plot_cluster_comparison.html](sklearn clustering examples) and add two more clustering algorithms of your choice to the comparisons above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Algo One\n",
    "from sklearn.cluster import AgglomerativeClustering, Birch\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target.astype(float)\n",
    "estimators = {'k_means_iris_3': KMeans(n_clusters=3),\n",
    "              'k_means_iris_8': KMeans(n_clusters=8),\n",
    "              'dbscan_iris_1': DBSCAN(eps=1),\n",
    "              'AgglomerativeClustering': AgglomerativeClustering(n_clusters=3),\n",
    "              'Birch': Birch()}\n",
    "\n",
    "for name, est in estimators.items():\n",
    "    est.fit(X)\n",
    "    labels = est.labels_\n",
    "    df[name] = labels\n",
    "\n",
    "\n",
    "\n",
    "name='Birch'\n",
    "    \n",
    "sns.pairplot(df,vars=['sepal_length',\n",
    "                    'sepal_width',\n",
    "                    'petal_length',\n",
    "                    'petal_width'],hue=name)\n",
    "print('completeness', name, homogeneity_score(df[name],df['species']))\n",
    "print('homogeneity', name, homogeneity_score(df['species'],df[name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Algo Two\n",
    "\n",
    "name='AgglomerativeClustering'\n",
    "    \n",
    "sns.pairplot(df,vars=['sepal_length',\n",
    "                    'sepal_width',\n",
    "                    'petal_length',\n",
    "                    'petal_width'],hue=name)\n",
    "print('completeness', name, homogeneity_score(df[name],df['species']))\n",
    "print('homogeneity', name, homogeneity_score(df['species'],df[name]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
