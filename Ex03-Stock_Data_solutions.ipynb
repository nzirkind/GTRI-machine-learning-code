{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Stock Data\n",
    "\n",
    "In this exercise, we will download some stock ticker data and process it with pandas.\n",
    "\n",
    "Install `pandas_datareader` with conda or pip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-01T01:07:39.788570Z",
     "start_time": "2018-07-31T21:07:36.830627-04:00"
    }
   },
   "outputs": [],
   "source": [
    "!pip install pandas_datareader==0.6\n",
    "!pip install pandas==0.22\n",
    "!pip freeze |grep pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-01T01:07:41.266151Z",
     "start_time": "2018-07-31T21:07:39.791934-04:00"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas_datareader import data, wb  \n",
    "import datetime\n",
    "\n",
    "# We will look at stock prices over the past year, starting at January 1, 2016\n",
    "start = datetime.datetime(2016,1,1)\n",
    "end = datetime.date.today()\n",
    " \n",
    "# Let's get Apple stock data; Apple's ticker symbol is AAPL\n",
    "# First argument is the series we want, second is the source (\"yahoo\" for Yahoo! Finance), third is the start date, fourth is the end date\n",
    "apple = data.get_data_quandl(\"AAPL\", start, end)\n",
    "apple.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas Basics\n",
    "\n",
    "- Take first `N` values: `df.head(N)`\n",
    "- Get data for one column: `df['column_name']` or `df.column_name`.\n",
    "- Get data for multiple columns of data: `df[['col1', 'col2']]`\n",
    "- Get data by a condition on the index: `df.query('Date>2017')`\n",
    "- Get data by a condition on the column: `df[df.Close>140]`\n",
    "- Summarize the data: `df.describe()`\n",
    "- Aggregate the data by 60 days: `df.groupby(pd.TimeGrouper(freq='60D')).mean()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-01T01:07:44.498957Z",
     "start_time": "2018-07-31T21:07:44.471530-04:00"
    }
   },
   "outputs": [],
   "source": [
    "apple.Low.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-01T01:07:44.834022Z",
     "start_time": "2018-07-31T21:07:44.823764-04:00"
    }
   },
   "outputs": [],
   "source": [
    "apple[['Low','High']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-01T01:07:45.260746Z",
     "start_time": "2018-07-31T21:07:45.207812-04:00"
    }
   },
   "outputs": [],
   "source": [
    "apple.query('Date>2017').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-01T01:07:45.735294Z",
     "start_time": "2018-07-31T21:07:45.712975-04:00"
    }
   },
   "outputs": [],
   "source": [
    "apple[apple.Close>140].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-01T01:07:46.278404Z",
     "start_time": "2018-07-31T21:07:46.230449-04:00"
    }
   },
   "outputs": [],
   "source": [
    "apple.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-01T01:07:46.877099Z",
     "start_time": "2018-07-31T21:07:46.845437-04:00"
    }
   },
   "outputs": [],
   "source": [
    "apple.groupby(pd.TimeGrouper(freq='60D')).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Daily Trend\n",
    "\n",
    "Capture the daily Low, High, and Close and plot those values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-01T01:07:57.495591Z",
     "start_time": "2018-07-31T21:07:57.118394-04:00"
    }
   },
   "outputs": [],
   "source": [
    "import pylab as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (15, 9)   # Change the size of plots\n",
    " \n",
    "apple[['AdjClose','Low','High']].plot(grid = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add More Stocks\n",
    "\n",
    "Grab the closing values from two more stocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-01T01:08:07.853899Z",
     "start_time": "2018-07-31T21:08:07.486863-04:00"
    }
   },
   "outputs": [],
   "source": [
    "microsoft = data.get_data_quandl(\"MSFT\", start, end)\n",
    "google = data.get_data_quandl(\"GOOG\", start, end)\n",
    " \n",
    "# Below I create a DataFrame consisting of the adjusted closing price of these stocks, first by making a list of these objects and using the join method\n",
    "stocks = pd.DataFrame({\"AAPL\": apple[\"Adj Close\"],\n",
    "                      \"MSFT\": microsoft[\"Adj Close\"],\n",
    "                      \"GOOG\": google[\"Adj Close\"]})\n",
    " \n",
    "stocks.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Price of all three stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot here\n",
    "stocks.plot(grid = True,logy=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply Rolling Window\n",
    "\n",
    "Read [http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.rolling.html](pd.rolling) and apply a 20-day rolling averaging window to the apple adjusted close."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stocks['AAPL']...\n",
    "ax = stocks['AAPL'].rolling(window=20, center=True).mean().plot(grid=True)\n",
    "ax = stocks['AAPL'].plot(grid=True,ax=ax)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Profit\n",
    "\n",
    "We'd like to normalize the share price so that we can fit all of the stock trends on one plot.  To do that let's normalize by the price on the start date for each stock.  Check the [http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.apply.html](pd.apply) documentation to apply this scaling to each column.\n",
    "\n",
    "Plot resulting profit time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply\n",
    "stock_return = stocks.apply(lambda x: x / x[0])\n",
    "stock_return.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_return.plot(grid = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S&P 500\n",
    "\n",
    "So far we manually specified a few ticker symbols.  In order to do larger scale analysis, we need to pull data for more tickers.  To do that, we need to find a data source with the ticker names.  Fortunately, Wikipedia has all of the S&P tickers in a html table at [https://en.wikipedia.org/wiki/List_of_S%26P_500_companies](https://en.wikipedia.org/wiki/List_of_S%26P_500_companies).  Use `pd.read_html` to grab this ticker data and then loop through all ticker and pull down the stock data for each ticker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://en.wikipedia.org/wiki/List_of_S%26P_500_companies'\n",
    "sp500 = pd.read_html(url,header=0)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = {}\n",
    "for ticker in sp500['Ticker symbol'][:200]:\n",
    "    try:\n",
    "        output[ticker] = data.get_data_quandl(ticker, start, end)['AdjClose']\n",
    "    except:\n",
    "        continue\n",
    "df_sp500 = pd.DataFrame(output)\n",
    "df_sp500.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Profit\n",
    "\n",
    "Create a new dataframe that calculates the profit for each stock and plot this profit across all stocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_return_sp500 = df_sp500.apply(lambda x: x / x[0])\n",
    "stock_return_sp500.plot(grid = True)\n",
    "plt.legend([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Profit Histogram\n",
    "\n",
    "Plot the histogram of the profit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(stock_return_sp500.ix[-1,:].dropna(),100)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Pandas to find high-performance stocks\n",
    "\n",
    "Retrun a list with all stock that doubled over the time period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_return_sp500.ix[-1,stock_return_sp500.ix[-1,:]>2]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
